# **WanfangPaperCrawler-Selenium**

万方数据平台论文爬虫，支持期刊论文元数据采集与智能解析

**项目简介**：本项目基于万方数据库获取学术论文，通过Selenium能够自动化地搜索指定关键词的论文，并提取论文的关键元数据，包括标题、作者、发表年份、期刊信息、摘要、关键词等，并支持csv或tsv两种格式输出。

**Selenium**：Selenium的名字来源于化学元素硒（Selenium），寓意其对“汞”（Mercury）测试工具的解毒作用。这一命名背后的含义在于，Selenium旨在解决由 Mercury 测试工具系列（如 QTP、QC、LR、WR 等）带来的高昂成本问题。这些工具虽然功能强大，但价格昂贵，使得许多测试人员对其又爱又恨。因此，ThoughtWorks 将他们的 Web 开源测试工具命名为 Selenium，意在帮助大家摆脱这些昂贵工具的束缚。

**项目实现**：wanfang.py可以直接运行，运行后打开chrome浏览器开始爬取（若是没有chrome浏览器建议根据自己的电脑版本提前安装，并配置环境变量）

**主要实现过程**：
1.浏览器初始化：配置完整的Chrome选项；通过CDP命令隐藏WebDriver特征。
2.构造搜索URL：使用URL参数构造精确搜索条件；设置论文列表遍历与详情页跳转机制。
3.信息提取：对每篇论文点击标题进入详情页，提取元数据后返回列表页；使用BeautifulSoup库进行多层级DOM解析；多重fallback机制；通过正则表达式处理特殊字符；结构化数据组织（字典形式）。
4.值得一提的是，代码中设置了关键词设置，在运行后手动输入，使用关键词直接加入到网址地址中的方法来跳转到具体的页面，并逐一点击每一个论文获取到他们的页面信息

ps：原本我使用的翻页方式是直接修改网页的页码，如从第二页开始是在网页后添加&p=2（不同网站可能不同，要注意，可能是page），手动添加人为点击确实可以实现跳转，但是万方的网页使用JavaScript实时渲染，实际上使用get操作的时候只能爬到一堆乱码或是根本定位不到元素。。。此方法失效，于是我们改为使用定位网站中“下一页”这个符号元素的位置，并模拟人类行为的点击它，从而成功实现跳转。

运行结果展示：

![image-20250403122917682](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20250403122917682.png)

数据保存展示：

![image-20250402231217262](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20250402231217262.png)

